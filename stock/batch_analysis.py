"""
æ‰¹é‡è‚¡ç¥¨åˆ†ææ¨¡å—
æä¾›æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨çš„åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§åˆ†æç±»å‹å’Œé…ç½®é€‰é¡¹
"""

import os
import sys
import time
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, asdict
import traceback

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

from stock.stock_data_tools import get_stock_tools
from stock.stock_code_map import get_stock_identity
from utils.format_utils import judge_rsi_level
from stock.batch_analysis_monitor import BatchAnalysisMonitor, ErrorHandler, ProgressReporter


@dataclass
class BatchAnalysisConfig:
    """æ‰¹é‡åˆ†æé…ç½®"""
    stock_codes: List[str]
    analysis_types: List[str]  # ['basic', 'technical', 'news', 'chip', 'comprehensive']
    use_cache: bool = True
    force_refresh: bool = False
    include_ai_analysis: bool = True
    max_workers: int = 3
    max_retry: int = 2
    user_opinion: str = ""
    user_position: str = "ä¸ç¡®å®š"
    output_dir: str = "./batch_analysis_results"
    save_individual_reports: bool = True
    save_summary_report: bool = True


@dataclass
class StockAnalysisResult:
    """å•åªè‚¡ç¥¨åˆ†æç»“æœ"""
    stock_code: str
    stock_name: str
    status: str  # 'success', 'failed', 'partial'
    error_message: Optional[str] = None
    analysis_data: Optional[Dict] = None
    analysis_time: Optional[str] = None
    summary: Optional[Dict] = None


@dataclass
class BatchAnalysisResult:
    """æ‰¹é‡åˆ†æç»“æœ"""
    config: BatchAnalysisConfig
    results: List[StockAnalysisResult]
    start_time: str
    end_time: str
    total_duration: float
    success_count: int
    failed_count: int
    summary_stats: Dict


class BatchStockAnalyzer:
    """æ‰¹é‡è‚¡ç¥¨åˆ†æå™¨"""
    
    def __init__(self, enable_monitoring: bool = True):
        """
        åˆå§‹åŒ–æ‰¹é‡åˆ†æå™¨
        
        Args:
            enable_monitoring: æ˜¯å¦å¯ç”¨ç›‘æ§åŠŸèƒ½
        """
        self.stock_tools = get_stock_tools()
        self.results = []
        self.enable_monitoring = enable_monitoring
        self.monitor = None
        self.error_handler = None
        self.progress_reporter = None
        
    def analyze_single_stock(self, stock_code: str, config: BatchAnalysisConfig) -> StockAnalysisResult:
        """åˆ†æå•åªè‚¡ç¥¨"""
        start_time = datetime.now()
        stock_name = ""
        analysis_data = {}
        errors = []
        
        # é€šçŸ¥ç›‘æ§å™¨å¼€å§‹åˆ†æ
        if self.monitor:
            self.monitor.update_stock_start(stock_code, stock_name)
        
        try:
            # è·å–è‚¡ç¥¨èº«ä»½ä¿¡æ¯
            stock_identity = get_stock_identity(stock_code)
            if not stock_identity:
                error_msg = f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„èº«ä»½ä¿¡æ¯"
                if self.monitor:
                    self.monitor.update_stock_complete(stock_code, success=False, error_message=error_msg)
                return StockAnalysisResult(
                    stock_code=stock_code,
                    stock_name="æœªçŸ¥",
                    status="failed",
                    error_message=error_msg
                )
            
            stock_name = stock_identity.get('name', '')
            print(f"ğŸ“Š å¼€å§‹åˆ†æ {stock_code} ({stock_name})")
            
            # æ›´æ–°ç›‘æ§å™¨è‚¡ç¥¨åç§°
            if self.monitor:
                self.monitor.update_stock_start(stock_code, stock_name)
            
            # æ ¹æ®é…ç½®è¿›è¡Œä¸åŒç±»å‹çš„åˆ†æ
            analysis_types = config.analysis_types
            total_types = len(analysis_types)
            
            for i, analysis_type in enumerate(analysis_types):
                # æ›´æ–°è¿›åº¦
                if self.monitor:
                    progress = (i / total_types) * 100
                    self.monitor.update_stock_progress(stock_code, progress, f"æ­£åœ¨æ‰§è¡Œ{analysis_type}åˆ†æ")
                
                if analysis_type == 'basic':
                    try:
                        basic_data = self.stock_tools.get_basic_info(
                            stock_identity, 
                            use_cache=config.use_cache,
                            force_refresh=config.force_refresh,
                            include_ai_analysis=config.include_ai_analysis
                        )
                        analysis_data['basic_info'] = basic_data
                    except Exception as e:
                        error_msg = f"åŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        print(f"âŒ {stock_code} {error_msg}")
                        
                        # ä½¿ç”¨é”™è¯¯å¤„ç†å™¨
                        if self.error_handler:
                            self.error_handler.handle_error(stock_code, e, "åŸºæœ¬é¢åˆ†æ")
            
                elif analysis_type == 'technical':
                    try:
                        kline_data = self.stock_tools.get_stock_kline_data(
                            stock_identity,
                            use_cache=config.use_cache,
                            force_refresh=config.force_refresh,
                            include_ai_analysis=config.include_ai_analysis
                        )
                        analysis_data['technical_analysis'] = kline_data
                    except Exception as e:
                        error_msg = f"æŠ€æœ¯åˆ†æå¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        print(f"âŒ {stock_code} {error_msg}")
                        
                        if self.error_handler:
                            self.error_handler.handle_error(stock_code, e, "æŠ€æœ¯åˆ†æ")
                
                elif analysis_type == 'news':
                    try:
                        news_data = self.stock_tools.get_stock_news_data(
                            stock_identity,
                            use_cache=config.use_cache,
                            force_refresh=config.force_refresh,
                            include_ai_analysis=config.include_ai_analysis
                        )
                        analysis_data['news_analysis'] = news_data
                    except Exception as e:
                        error_msg = f"æ–°é—»åˆ†æå¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        print(f"âŒ {stock_code} {error_msg}")
                        
                        if self.error_handler:
                            self.error_handler.handle_error(stock_code, e, "æ–°é—»åˆ†æ")
                
                elif analysis_type == 'chip':
                    try:
                        chip_data = self.stock_tools.get_stock_chip_data(
                            stock_identity,
                            use_cache=config.use_cache,
                            force_refresh=config.force_refresh,
                            include_ai_analysis=config.include_ai_analysis
                        )
                        analysis_data['chip_analysis'] = chip_data
                    except Exception as e:
                        error_msg = f"ç­¹ç åˆ†æå¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        print(f"âŒ {stock_code} {error_msg}")
                        
                        if self.error_handler:
                            self.error_handler.handle_error(stock_code, e, "ç­¹ç åˆ†æ")
                
                elif analysis_type == 'comprehensive':
                    try:
                        comprehensive_data = self.stock_tools.get_comprehensive_ai_analysis(
                            stock_identity,
                            user_opinion=config.user_opinion,
                            user_position=config.user_position,
                            use_cache=config.use_cache,
                            force_refresh=config.force_refresh
                        )
                        analysis_data['comprehensive_analysis'] = comprehensive_data
                    except Exception as e:
                        error_msg = f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        print(f"âŒ {stock_code} {error_msg}")
                        
                        if self.error_handler:
                            self.error_handler.handle_error(stock_code, e, "ç»¼åˆåˆ†æ")
            
            # ç”Ÿæˆè‚¡ç¥¨æ‘˜è¦
            summary = self._generate_stock_summary(analysis_data)
            
            # ç¡®å®šåˆ†æçŠ¶æ€
            if not errors:
                status = "success"
            elif len(errors) < len(config.analysis_types):
                status = "partial"
            else:
                status = "failed"
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            result = StockAnalysisResult(
                stock_code=stock_code,
                stock_name=stock_name,
                status=status,
                error_message="; ".join(errors) if errors else None,
                analysis_data=analysis_data,
                analysis_time=end_time.strftime('%Y-%m-%d %H:%M:%S'),
                summary=summary
            )
            
            # é€šçŸ¥ç›‘æ§å™¨åˆ†æå®Œæˆ
            if self.monitor:
                self.monitor.update_stock_complete(stock_code, success=(status != "failed"), 
                                                 error_message=result.error_message)
            
            print(f"âœ… {stock_code} ({stock_name}) åˆ†æå®Œæˆ - çŠ¶æ€: {status}")
            return result
            
        except Exception as e:
            error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
            print(f"âŒ {stock_code} {error_msg}")
            traceback.print_exc()
            
            # ä½¿ç”¨é”™è¯¯å¤„ç†å™¨
            if self.error_handler:
                self.error_handler.handle_error(stock_code, e, "æœªçŸ¥é”™è¯¯")
            
            # é€šçŸ¥ç›‘æ§å™¨åˆ†æå¤±è´¥
            if self.monitor:
                self.monitor.update_stock_complete(stock_code, success=False, error_message=error_msg)
            
            return StockAnalysisResult(
                stock_code=stock_code,
                stock_name=stock_name,
                status="failed",
                error_message=error_msg,
                analysis_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            )
    
    def _generate_stock_summary(self, analysis_data: Dict) -> Dict:
        """ç”Ÿæˆè‚¡ç¥¨åˆ†ææ‘˜è¦"""
        summary = {
            'current_price': 0,
            'change_percent': 0,
            'industry': '',
            'technical_trend': 'æœªçŸ¥',
            'rsi_level': 'ä¸­æ€§',
            'news_count': 0,
            'profit_ratio': 0,
            'analysis_count': 0,
            'has_ai_analysis': False
        }
        
        # åŸºæœ¬ä¿¡æ¯æ‘˜è¦
        if 'basic_info' in analysis_data and analysis_data['basic_info']:
            basic = analysis_data['basic_info']
            if 'error' not in basic:
                summary['current_price'] = basic.get('current_price', 0)
                summary['change_percent'] = basic.get('change_percent', 0)
                summary['industry'] = basic.get('industry', '')
                summary['analysis_count'] += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰AIåˆ†æ
                if 'ai_analysis' in basic and 'error' not in basic.get('ai_analysis', {}):
                    summary['has_ai_analysis'] = True
        
        # æŠ€æœ¯åˆ†ææ‘˜è¦
        if 'technical_analysis' in analysis_data and analysis_data['technical_analysis']:
            tech = analysis_data['technical_analysis']
            if 'error' not in tech:
                indicators = tech.get('indicators', {})
                summary['technical_trend'] = f"{indicators.get('ma_trend', 'æœªçŸ¥')} | MACD {indicators.get('macd_trend', 'æœªçŸ¥')}"
                summary['rsi_level'] = judge_rsi_level(indicators.get('rsi_14', 50))
                summary['analysis_count'] += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰AIåˆ†æ
                if 'ai_analysis' in tech and 'error' not in tech.get('ai_analysis', {}):
                    summary['has_ai_analysis'] = True
        
        # æ–°é—»åˆ†ææ‘˜è¦
        if 'news_analysis' in analysis_data and analysis_data['news_analysis']:
            news = analysis_data['news_analysis']
            if 'error' not in news:
                summary['news_count'] = news.get('news_count', 0)
                summary['analysis_count'] += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰AIåˆ†æ
                if 'ai_analysis' in news and 'error' not in news.get('ai_analysis', {}):
                    summary['has_ai_analysis'] = True
        
        # ç­¹ç åˆ†ææ‘˜è¦
        if 'chip_analysis' in analysis_data and analysis_data['chip_analysis']:
            chip = analysis_data['chip_analysis']
            if 'error' not in chip:
                summary['profit_ratio'] = chip.get('profit_ratio', 0)
                summary['analysis_count'] += 1
                
                # æ£€æŸ¥æ˜¯å¦æœ‰AIåˆ†æ
                if 'ai_analysis' in chip and 'error' not in chip.get('ai_analysis', {}):
                    summary['has_ai_analysis'] = True
        
        # ç»¼åˆåˆ†ææ‘˜è¦
        if 'comprehensive_analysis' in analysis_data and analysis_data['comprehensive_analysis']:
            comp = analysis_data['comprehensive_analysis']
            if 'error' not in comp:
                summary['analysis_count'] += 1
                summary['has_ai_analysis'] = True
        
        return summary
    
    def batch_analyze(self, config: BatchAnalysisConfig) -> BatchAnalysisResult:
        """æ‰§è¡Œæ‰¹é‡åˆ†æ"""
        start_time = datetime.now()
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ {len(config.stock_codes)} åªè‚¡ç¥¨")
        print(f"ğŸ“‹ åˆ†æç±»å‹: {', '.join(config.analysis_types)}")
        print(f"ğŸ”§ å¹¶å‘æ•°: {config.max_workers}")
        print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜: {config.use_cache}")
        print(f"ğŸ¤– AIåˆ†æ: {config.include_ai_analysis}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ç›‘æ§ç»„ä»¶
        if self.enable_monitoring:
            self.monitor = BatchAnalysisMonitor(len(config.stock_codes))
            self.error_handler = ErrorHandler(self.monitor)
            self.progress_reporter = ProgressReporter(self.monitor)
            self.monitor.start_monitoring()
        
        results = []
        success_count = 0
        failed_count = 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘åˆ†æ
        with ThreadPoolExecutor(max_workers=config.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_stock = {
                executor.submit(self.analyze_single_stock, stock_code, config): stock_code 
                for stock_code in config.stock_codes
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_stock):
                stock_code = future_to_stock[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    if result.status == "success":
                        success_count += 1
                    else:
                        failed_count += 1
                    
                    # å®šæœŸæŠ¥å‘Šè¿›åº¦
                    if self.progress_reporter and self.progress_reporter.should_report():
                        self.progress_reporter.report_progress()
                        
                except Exception as e:
                    print(f"âŒ {stock_code} åˆ†æä»»åŠ¡å¼‚å¸¸: {str(e)}")
                    failed_count += 1
                    
                    # ä½¿ç”¨é”™è¯¯å¤„ç†å™¨
                    if self.error_handler:
                        self.error_handler.handle_error(stock_code, e, "ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸")
                    
                    results.append(StockAnalysisResult(
                        stock_code=stock_code,
                        stock_name="æœªçŸ¥",
                        status="failed",
                        error_message=f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                    ))
        
        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds()
        
        # åœæ­¢ç›‘æ§
        if self.monitor:
            self.monitor.stop_monitoring()
            
            # ä¿å­˜ç›‘æ§æ—¥å¿—
            monitor_log_path = os.path.join(config.output_dir, "monitor_log.json")
            self.monitor.save_monitor_log(monitor_log_path)
        
        # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
        summary_stats = self._generate_summary_stats(results)
        
        batch_result = BatchAnalysisResult(
            config=config,
            results=results,
            start_time=start_time.strftime('%Y-%m-%d %H:%M:%S'),
            end_time=end_time.strftime('%Y-%m-%d %H:%M:%S'),
            total_duration=total_duration,
            success_count=success_count,
            failed_count=failed_count,
            summary_stats=summary_stats
        )
        
        # ä¿å­˜ç»“æœ
        if config.save_individual_reports:
            self._save_individual_reports(batch_result)
        
        if config.save_summary_report:
            self._save_summary_report(batch_result)
        
        print(f"\nâœ… æ‰¹é‡åˆ†æå®Œæˆ!")
        print(f"ğŸ“Š æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print(f"âœ… æˆåŠŸ: {success_count} åª")
        print(f"âŒ å¤±è´¥: {failed_count} åª")
        print(f"ğŸ“ ç»“æœç›®å½•: {config.output_dir}")
        
        # æ˜¾ç¤ºé”™è¯¯æ‘˜è¦
        if self.monitor and failed_count > 0:
            error_summary = self.monitor.get_error_summary()
            print(f"\nâŒ é”™è¯¯æ‘˜è¦:")
            print(f"   æ€»é”™è¯¯æ•°: {error_summary['total_errors']}")
            if error_summary['common_errors']:
                print(f"   å¸¸è§é”™è¯¯:")
                for error_msg, count in list(error_summary['common_errors'].items())[:3]:
                    print(f"     - {error_msg} ({count}æ¬¡)")
        
        return batch_result
    
    def _generate_summary_stats(self, results: List[StockAnalysisResult]) -> Dict:
        """ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_stocks': len(results),
            'success_rate': 0,
            'avg_analysis_time': 0,
            'industry_distribution': {},
            'price_ranges': {'low': 0, 'medium': 0, 'high': 0},
            'trend_distribution': {},
            'ai_analysis_coverage': 0
        }
        
        if not results:
            return stats
        
        success_count = sum(1 for r in results if r.status == "success")
        stats['success_rate'] = success_count / len(results) * 100
        
        # ç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
        for result in results:
            if result.summary and result.summary.get('industry'):
                industry = result.summary['industry']
                stats['industry_distribution'][industry] = stats['industry_distribution'].get(industry, 0) + 1
        
        # ç»Ÿè®¡ä»·æ ¼åŒºé—´
        for result in results:
            if result.summary and result.summary.get('current_price', 0) > 0:
                price = result.summary['current_price']
                if price < 20:
                    stats['price_ranges']['low'] += 1
                elif price < 100:
                    stats['price_ranges']['medium'] += 1
                else:
                    stats['price_ranges']['high'] += 1
        
        # ç»Ÿè®¡AIåˆ†æè¦†ç›–ç‡
        ai_count = sum(1 for r in results if r.summary and r.summary.get('has_ai_analysis', False))
        stats['ai_analysis_coverage'] = ai_count / len(results) * 100
        
        return stats
    
    def _make_json_safe(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå®‰å…¨æ ¼å¼ï¼ˆå¤„ç†DataFrameç­‰ä¸å¯åºåˆ—åŒ–å¯¹è±¡ï¼‰"""
        import numpy as np
        import pandas as pd
        
        if isinstance(obj, dict):
            return {key: self._make_json_safe(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_safe(item) for item in obj]
        elif isinstance(obj, pd.Series):
            return obj.tolist()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif isinstance(obj, (np.integer, np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        elif hasattr(obj, 'isoformat'):
            return obj.isoformat()
        else:
            return obj
    
    def _save_individual_reports(self, batch_result: BatchAnalysisResult):
        """ä¿å­˜å•åªè‚¡ç¥¨çš„åˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for result in batch_result.results:
            if result.analysis_data:
                # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†æ•°æ®
                filename = f"{result.stock_code}_{result.stock_name}_{timestamp}.json"
                filepath = os.path.join(batch_result.config.output_dir, filename)
                
                report_data = {
                    'stock_code': result.stock_code,
                    'stock_name': result.stock_name,
                    'analysis_time': result.analysis_time,
                    'status': result.status,
                    'summary': result.summary,
                    'analysis_data': result.analysis_data
                }
                
                try:
                    # è½¬æ¢ä¸ºJSONå®‰å…¨æ ¼å¼
                    safe_report_data = self._make_json_safe(report_data)
                    with open(filepath, 'w', encoding='utf-8') as f:
                        json.dump(safe_report_data, f, ensure_ascii=False, indent=2)
                    print(f"ğŸ’¾ å·²ä¿å­˜ {result.stock_code} è¯¦ç»†æŠ¥å‘Š: {filename}")
                except Exception as e:
                    print(f"âŒ ä¿å­˜ {result.stock_code} æŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    def _save_summary_report(self, batch_result: BatchAnalysisResult):
        """ä¿å­˜æ±‡æ€»æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜æ±‡æ€»CSV
        csv_filename = f"batch_analysis_summary_{timestamp}.csv"
        csv_filepath = os.path.join(batch_result.config.output_dir, csv_filename)
        
        summary_data = []
        for result in batch_result.results:
            row = {
                'è‚¡ç¥¨ä»£ç ': result.stock_code,
                'è‚¡ç¥¨åç§°': result.stock_name,
                'åˆ†æçŠ¶æ€': result.status,
                'å½“å‰ä»·æ ¼': result.summary.get('current_price', 0) if result.summary else 0,
                'æ¶¨è·Œå¹…(%)': result.summary.get('change_percent', 0) if result.summary else 0,
                'è¡Œä¸š': result.summary.get('industry', '') if result.summary else '',
                'æŠ€æœ¯è¶‹åŠ¿': result.summary.get('technical_trend', '') if result.summary else '',
                'RSIæ°´å¹³': result.summary.get('rsi_level', '') if result.summary else '',
                'æ–°é—»æ•°é‡': result.summary.get('news_count', 0) if result.summary else 0,
                'ç›ˆåˆ©æ¯”ä¾‹(%)': result.summary.get('profit_ratio', 0) if result.summary else 0,
                'åˆ†æå®Œæˆæ•°': result.summary.get('analysis_count', 0) if result.summary else 0,
                'åŒ…å«AIåˆ†æ': 'æ˜¯' if result.summary and result.summary.get('has_ai_analysis') else 'å¦',
                'é”™è¯¯ä¿¡æ¯': result.error_message or '',
                'åˆ†ææ—¶é—´': result.analysis_time or ''
            }
            summary_data.append(row)
        
        try:
            df = pd.DataFrame(summary_data)
            df.to_csv(csv_filepath, index=False, encoding='utf-8-sig')
            print(f"ğŸ“Š å·²ä¿å­˜æ±‡æ€»CSV: {csv_filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ±‡æ€»CSVå¤±è´¥: {str(e)}")
        
        # ä¿å­˜è¯¦ç»†æ±‡æ€»JSON
        json_filename = f"batch_analysis_detailed_{timestamp}.json"
        json_filepath = os.path.join(batch_result.config.output_dir, json_filename)
        
        detailed_report = {
            'batch_info': {
                'start_time': batch_result.start_time,
                'end_time': batch_result.end_time,
                'total_duration': batch_result.total_duration,
                'success_count': batch_result.success_count,
                'failed_count': batch_result.failed_count,
                'config': asdict(batch_result.config)
            },
            'summary_stats': batch_result.summary_stats,
            'results': [asdict(result) for result in batch_result.results]
        }
        
        try:
            # è½¬æ¢ä¸ºJSONå®‰å…¨æ ¼å¼
            safe_detailed_report = self._make_json_safe(detailed_report)
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(safe_detailed_report, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“‹ å·²ä¿å­˜è¯¦ç»†æ±‡æ€»: {json_filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜è¯¦ç»†æ±‡æ€»å¤±è´¥: {str(e)}")


# ä¾¿æ·å‡½æ•°
def create_default_config(stock_codes: List[str], analysis_types: List[str] = None) -> BatchAnalysisConfig:
    """åˆ›å»ºé»˜è®¤çš„æ‰¹é‡åˆ†æé…ç½®"""
    if analysis_types is None:
        analysis_types = ['basic', 'technical', 'news', 'comprehensive']
    
    return BatchAnalysisConfig(
        stock_codes=stock_codes,
        analysis_types=analysis_types,
        use_cache=True,
        force_refresh=False,
        include_ai_analysis=True,
        max_workers=3,
        max_retry=2,
        output_dir=f"./batch_analysis_results/{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    )


def quick_batch_analyze(stock_codes: List[str], analysis_types: List[str] = None) -> BatchAnalysisResult:
    """å¿«é€Ÿæ‰¹é‡åˆ†æ"""
    config = create_default_config(stock_codes, analysis_types)
    analyzer = BatchStockAnalyzer()
    return analyzer.batch_analyze(config)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    test_codes = ["000001", "600519", "300750"]
    result = quick_batch_analyze(test_codes, ['basic', 'technical'])
    print(f"åˆ†æå®Œæˆï¼ŒæˆåŠŸ: {result.success_count}, å¤±è´¥: {result.failed_count}")
