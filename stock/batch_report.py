"""
æ‰¹é‡åˆ†ææŠ¥å‘Šç”Ÿæˆæ¨¡å—
ä¸ºæ‰¹é‡åˆ†æç»“æœç”Ÿæˆå„ç§æ ¼å¼çš„æŠ¥å‘Š
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

from utils.report_utils import generate_pdf_report, generate_docx_report, generate_markdown_file, generate_html_report
from version import get_full_version


def generate_batch_analysis_report(batch_result_dir: str, format_type: str = "pdf") -> bytes:
    """
    ç”Ÿæˆæ‰¹é‡åˆ†ææŠ¥å‘Š
    
    Args:
        batch_result_dir: æ‰¹é‡åˆ†æç»“æœç›®å½•
        format_type: æŠ¥å‘Šæ ¼å¼ (pdf, docx, html, markdown)
    
    Returns:
        æŠ¥å‘Šå†…å®¹çš„å­—èŠ‚æ•°æ®
    """
    try:
        # è¯»å–æ‰¹é‡åˆ†æç»“æœ
        batch_data = _load_batch_analysis_data(batch_result_dir)
        if not batch_data:
            error_msg = "æ— æ³•åŠ è½½æ‰¹é‡åˆ†ææ•°æ®"
            return _generate_error_report(error_msg, format_type)
        
        # ç”ŸæˆMarkdownå†…å®¹
        md_content = _generate_markdown_content(batch_data)
        
        # è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼
        if format_type == "pdf":
            return generate_pdf_report(md_content)
        elif format_type == "docx":
            return generate_docx_report(md_content)
        elif format_type == "html":
            return generate_html_report(md_content)
        elif format_type == "markdown":
            return generate_markdown_file(md_content)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
            
    except Exception as e:
        error_msg = f"ç”Ÿæˆæ‰¹é‡åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}"
        return _generate_error_report(error_msg, format_type)


def generate_individual_stock_reports(batch_result_dir: str, format_type: str = "pdf") -> Dict[str, bytes]:
    """
    ä¸ºæ¯åªè‚¡ç¥¨ç”Ÿæˆç‹¬ç«‹çš„å®Œæ•´åˆ†ææŠ¥å‘Š
    
    Args:
        batch_result_dir: æ‰¹é‡åˆ†æç»“æœç›®å½•
        format_type: æŠ¥å‘Šæ ¼å¼ (pdf, docx, html, markdown)
    
    Returns:
        å­—å…¸ï¼Œé”®ä¸ºè‚¡ç¥¨ä»£ç ï¼Œå€¼ä¸ºæŠ¥å‘Šå†…å®¹çš„å­—èŠ‚æ•°æ®
    """
    try:
        # è¯»å–æ‰¹é‡åˆ†æç»“æœ
        batch_data = _load_batch_analysis_data(batch_result_dir)
        if not batch_data:
            raise Exception("æ— æ³•åŠ è½½æ‰¹é‡åˆ†ææ•°æ®")
        
        detailed = batch_data['detailed']
        results = detailed['results']
        
        individual_reports = {}
        
        for result in results:
            if result['status'] == 'success':
                stock_code = result['stock_code']
                stock_name = result['stock_name']
                
                # ç”Ÿæˆå•åªè‚¡ç¥¨çš„å®Œæ•´æŠ¥å‘Š
                md_content = _generate_individual_stock_markdown(result, detailed['batch_info'])
                
                # è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼
                if format_type == "pdf":
                    report_content = generate_pdf_report(md_content)
                elif format_type == "docx":
                    report_content = generate_docx_report(md_content)
                elif format_type == "html":
                    report_content = generate_html_report(md_content)
                elif format_type == "markdown":
                    report_content = generate_markdown_file(md_content)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
                
                individual_reports[stock_code] = report_content
                print(f"âœ… å·²ç”Ÿæˆ {stock_name}({stock_code}) çš„{format_type.upper()}æŠ¥å‘Š")
        
        return individual_reports
        
    except Exception as e:
        error_msg = f"ç”Ÿæˆä¸ªè‚¡æŠ¥å‘Šå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return {}


def export_all_individual_reports(batch_result_dir: str, format_type: str = "pdf", output_dir: str = None) -> List[str]:
    """
    å¯¼å‡ºæ‰€æœ‰ä¸ªè‚¡çš„ç‹¬ç«‹æŠ¥å‘Šåˆ°æ–‡ä»¶
    
    Args:
        batch_result_dir: æ‰¹é‡åˆ†æç»“æœç›®å½•
        format_type: æŠ¥å‘Šæ ¼å¼ (pdf, docx, html, markdown)
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨batch_result_dir
    
    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    if output_dir is None:
        output_dir = batch_result_dir
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆæ‰€æœ‰ä¸ªè‚¡æŠ¥å‘Š
    individual_reports = generate_individual_stock_reports(batch_result_dir, format_type)
    
    generated_files = []
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    for stock_code, report_content in individual_reports.items():
        # è·å–è‚¡ç¥¨åç§°
        batch_data = _load_batch_analysis_data(batch_result_dir)
        stock_name = ""
        for result in batch_data['detailed']['results']:
            if result['stock_code'] == stock_code:
                stock_name = result['stock_name']
                break
        
        # ç”Ÿæˆæ–‡ä»¶å
        safe_stock_name = stock_name.replace(' ', '_').replace('*', '').replace('/', '_')
        filename = f"{stock_code}_{safe_stock_name}_å®Œæ•´åˆ†ææŠ¥å‘Š_{timestamp}.{format_type}"
        filepath = os.path.join(output_dir, filename)
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'wb') as f:
            f.write(report_content)
        
        generated_files.append(filepath)
        print(f"ğŸ“„ å·²ä¿å­˜: {filename}")
    
    return generated_files


def _load_batch_analysis_data(batch_result_dir: str) -> Optional[Dict]:
    """åŠ è½½æ‰¹é‡åˆ†ææ•°æ®"""
    try:
        # æŸ¥æ‰¾è¯¦ç»†æ±‡æ€»æ–‡ä»¶
        files = os.listdir(batch_result_dir)
        detailed_file = None
        summary_file = None
        
        for file in files:
            if file.startswith("batch_analysis_detailed_") and file.endswith(".json"):
                detailed_file = file
            elif file.startswith("batch_analysis_summary_") and file.endswith(".csv"):
                summary_file = file
        
        if not detailed_file:
            return None
        
        # è¯»å–è¯¦ç»†æ•°æ®
        detailed_path = os.path.join(batch_result_dir, detailed_file)
        with open(detailed_path, 'r', encoding='utf-8') as f:
            detailed_data = json.load(f)
        
        # è¯»å–æ±‡æ€»æ•°æ®
        summary_data = None
        if summary_file:
            summary_path = os.path.join(batch_result_dir, summary_file)
            summary_data = pd.read_csv(summary_path, encoding='utf-8-sig')
        
        return {
            'detailed': detailed_data,
            'summary': summary_data,
            'result_dir': batch_result_dir
        }
        
    except Exception as e:
        print(f"åŠ è½½æ‰¹é‡åˆ†ææ•°æ®å¤±è´¥: {e}")
        return None


def _generate_individual_stock_markdown(result: Dict, batch_info: Dict) -> str:
    """ç”Ÿæˆå•åªè‚¡ç¥¨çš„å®Œæ•´åˆ†ææŠ¥å‘ŠMarkdownå†…å®¹"""
    stock_code = result['stock_code']
    stock_name = result['stock_name']
    analysis_data = result.get('analysis_data', {})
    summary = result.get('summary', {})
    
    # è·å–ç‰ˆæœ¬ä¿¡æ¯
    version_info = get_full_version()
    
    # å¼€å§‹ç”Ÿæˆå†…å®¹
    content = f"""# {stock_name}({stock_code}) å®Œæ•´åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†ææ¦‚è§ˆ

**è‚¡ç¥¨ä»£ç **: {stock_code}  
**è‚¡ç¥¨åç§°**: {stock_name}  
**åˆ†ææ—¶é—´**: {result['analysis_time']}  
**åˆ†æçŠ¶æ€**: {result['status']}  
**å½“å‰ä»·æ ¼**: {summary.get('current_price', 'N/A')}  
**æ¶¨è·Œå¹…**: {summary.get('change_percent', 'N/A')}%  
**æŠ€æœ¯è¶‹åŠ¿**: {summary.get('technical_trend', 'N/A')}  
**RSIæ°´å¹³**: {summary.get('rsi_level', 'N/A')}  
**æ–°é—»æ•°é‡**: {summary.get('news_count', 0)}  
**ç›ˆåˆ©æ¯”ä¾‹**: {summary.get('profit_ratio', 0)}%  
**åˆ†æå®Œæˆæ•°**: {summary.get('analysis_count', 0)}  
**åŒ…å«AIåˆ†æ**: {'æ˜¯' if summary.get('has_ai_analysis', False) else 'å¦'}  

**ç³»ç»Ÿç‰ˆæœ¬**: {version_info}

---

"""
    
    # 1. åŸºæœ¬ä¿¡æ¯éƒ¨åˆ†
    content += """# ğŸ“‹ åŸºæœ¬ä¿¡æ¯

"""
    
    basic_info = analysis_data.get('basic_info', {})
    if basic_info and 'error' not in basic_info:
        content += "## å…¬å¸åŸºæœ¬ä¿¡æ¯\n\n"
        
        # åŸºæœ¬ä¿¡æ¯è¡¨æ ¼
        content += "| é¡¹ç›® | æ•°å€¼ |\n"
        content += "|------|------|\n"
        
        basic_fields = [
            ('è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ä»£ç '),
            ('è‚¡ç¥¨åç§°', 'è‚¡ç¥¨åç§°'),
            ('å½“å‰ä»·æ ¼', 'current_price'),
            ('æ¶¨è·Œå¹…', 'change_percent'),
            ('æˆäº¤é‡', 'volume'),
            ('æˆäº¤é¢', 'amount'),
            ('æœ€é«˜ä»·', 'high'),
            ('æœ€ä½ä»·', 'low'),
            ('å¼€ç›˜ä»·', 'open'),
            ('æ‰€å¤„è¡Œä¸š', 'æ‰€å¤„è¡Œä¸š'),
            ('å¸‚ç›ˆç‡', 'å¸‚ç›ˆç‡'),
            ('å¸‚å‡€ç‡', 'å¸‚å‡€ç‡'),
            ('æ€»å¸‚å€¼', 'æ€»å¸‚å€¼'),
            ('æµé€šå¸‚å€¼', 'æµé€šå¸‚å€¼'),
            ('å‡€èµ„äº§æ”¶ç›Šç‡(ROE)', 'å‡€èµ„äº§æ”¶ç›Šç‡(ROE)'),
            ('æ¯›åˆ©ç‡', 'æ¯›åˆ©ç‡'),
            ('é”€å”®å‡€åˆ©ç‡', 'é”€å”®å‡€åˆ©ç‡'),
            ('èµ„äº§è´Ÿå€ºç‡', 'èµ„äº§è´Ÿå€ºç‡'),
            ('åŸºæœ¬æ¯è‚¡æ”¶ç›Š', 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š'),
            ('æ¯è‚¡å‡€èµ„äº§', 'æ¯è‚¡å‡€èµ„äº§')
        ]
        
        for display_name, field_name in basic_fields:
            value = basic_info.get(field_name, 'N/A')
            if isinstance(value, float):
                if field_name in ['current_price', 'high', 'low', 'open']:
                    value = f"{value:.2f}"
                elif field_name in ['change_percent']:
                    value = f"{value:.2f}%"
                elif field_name in ['volume']:
                    value = f"{int(value):,}"
                elif field_name in ['amount']:
                    value = f"{value:,.0f}"
                elif field_name in ['æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼']:
                    value = f"{value:,.0f}"
            content += f"| {display_name} | {value} |\n"
        
        content += "\n"
        
        # åˆ†çº¢ä¿¡æ¯
        if 'è¿‘å¹´åˆ†çº¢è¯¦æƒ…' in basic_info:
            content += "## åˆ†çº¢ä¿¡æ¯\n\n"
            content += "| å¹´ä»½ | åˆ†çº¢ç±»å‹ | é€è‚¡æ¯”ä¾‹ | è½¬å¢æ¯”ä¾‹ | æ´¾æ¯æ¯”ä¾‹ |\n"
            content += "|------|----------|----------|----------|----------|\n"
            
            for dividend in basic_info['è¿‘å¹´åˆ†çº¢è¯¦æƒ…']:
                content += f"| {dividend.get('å¹´ä»½', 'N/A')} | {dividend.get('åˆ†çº¢ç±»å‹', 'N/A')} | {dividend.get('é€è‚¡æ¯”ä¾‹', 0)} | {dividend.get('è½¬å¢æ¯”ä¾‹', 0)} | {dividend.get('æ´¾æ¯æ¯”ä¾‹', 0)} |\n"
            
            content += "\n"
        
        # AIåŸºæœ¬é¢åˆ†æ
        if 'fundamental_ai' in analysis_data:
            ai_result = analysis_data['fundamental_ai']
            if ai_result.get('analysis_result'):
                content += "## ğŸ¤– AIåŸºæœ¬é¢åˆ†æ\n\n"
                content += f"{ai_result['analysis_result']}\n\n"
                content += f"*åˆ†æç”Ÿæˆæ—¶é—´: {ai_result.get('timestamp', 'N/A')}*\n\n"
        
        # AIå…¬å¸åˆ†æ
        if 'company_ai' in analysis_data:
            ai_result = analysis_data['company_ai']
            if ai_result.get('analysis_result'):
                content += "## ğŸ¢ AIå…¬å¸åˆ†æ\n\n"
                content += f"{ai_result['analysis_result']}\n\n"
                content += f"*åˆ†æç”Ÿæˆæ—¶é—´: {ai_result.get('timestamp', 'N/A')}*\n\n"
    else:
        content += "åŸºæœ¬ä¿¡æ¯è·å–å¤±è´¥æˆ–æ•°æ®ä¸å®Œæ•´ã€‚\n\n"
    
    content += "---\n\n"
    
    # 2. è¡Œæƒ…èµ°åŠ¿éƒ¨åˆ†
    content += """# ğŸ“ˆ è¡Œæƒ…èµ°åŠ¿

"""
    
    technical_info = analysis_data.get('technical_analysis', {})
    if technical_info and 'error' not in technical_info:
        content += "## æŠ€æœ¯æŒ‡æ ‡åˆ†æ\n\n"
        
        # æŠ€æœ¯æŒ‡æ ‡è¡¨æ ¼
        indicators = technical_info.get('indicators', {})
        if indicators:
            content += "| æŒ‡æ ‡åç§° | æ•°å€¼ |\n"
            content += "|----------|------|\n"
            
            indicator_fields = [
                ('MA5', 'ma_5'),
                ('MA10', 'ma_10'),
                ('MA20', 'ma_20'),
                ('MA60', 'ma_60'),
                ('EMA12', 'ema_12'),
                ('EMA26', 'ema_26'),
                ('MACD', 'macd'),
                ('MACDä¿¡å·çº¿', 'macd_signal'),
                ('MACDæŸ±çŠ¶å›¾', 'macd_histogram'),
                ('KDJ-K', 'kdj_k'),
                ('KDJ-D', 'kdj_d'),
                ('KDJ-J', 'kdj_j'),
                ('RSI14', 'rsi_14'),
                ('å¸ƒæ—ä¸Šè½¨', 'boll_upper'),
                ('å¸ƒæ—ä¸­è½¨', 'boll_middle'),
                ('å¸ƒæ—ä¸‹è½¨', 'boll_lower'),
                ('å¨å»‰æŒ‡æ ‡', 'wr_14'),
                ('CCIæŒ‡æ ‡', 'cci_14')
            ]
            
            for display_name, field_name in indicator_fields:
                value = indicators.get(field_name)
                if value is not None:
                    if isinstance(value, float):
                        value = f"{value:.4f}"
                else:
                    value = 'N/A'
                content += f"| {display_name} | {value} |\n"
            
            content += "\n"
        
        # è¶‹åŠ¿åˆ†æ
        if indicators.get('ma_trend'):
            content += f"**ç§»åŠ¨å¹³å‡çº¿è¶‹åŠ¿**: {indicators['ma_trend']}\n\n"
        if indicators.get('macd_trend'):
            content += f"**MACDè¶‹åŠ¿**: {indicators['macd_trend']}\n\n"
        
        # é£é™©æŒ‡æ ‡
        risk_metrics = technical_info.get('risk_metrics', {})
        if risk_metrics:
            content += "## é£é™©æŒ‡æ ‡\n\n"
            content += "| é£é™©æŒ‡æ ‡ | æ•°å€¼ |\n"
            content += "|----------|------|\n"
            
            risk_fields = [
                ('å¹´åŒ–æ³¢åŠ¨ç‡', 'annualized_volatility'),
                ('æœ€å¤§å›æ’¤', 'max_drawdown'),
                ('å¤æ™®æ¯”ç‡', 'sharpe_ratio'),
                ('VaR(95%)', 'var_95'),
                ('CVaR(95%)', 'cvar_95')
            ]
            
            for display_name, field_name in risk_fields:
                value = risk_metrics.get(field_name)
                if value is not None:
                    if isinstance(value, float):
                        value = f"{value:.4f}"
                else:
                    value = 'N/A'
                content += f"| {display_name} | {value} |\n"
            
            content += "\n"
        
        # AIæŠ€æœ¯åˆ†æ
        if 'technical_ai' in analysis_data:
            ai_result = analysis_data['technical_ai']
            if ai_result.get('analysis_result'):
                content += "## ğŸ¤– AIæŠ€æœ¯åˆ†æ\n\n"
                content += f"{ai_result['analysis_result']}\n\n"
                content += f"*åˆ†æç”Ÿæˆæ—¶é—´: {ai_result.get('timestamp', 'N/A')}*\n\n"
    else:
        content += "æŠ€æœ¯åˆ†ææ•°æ®è·å–å¤±è´¥æˆ–æ•°æ®ä¸å®Œæ•´ã€‚\n\n"
    
    content += "---\n\n"
    
    # 3. æ–°é—»èµ„è®¯éƒ¨åˆ†
    content += """# ğŸ“° æ–°é—»èµ„è®¯

"""
    
    news_info = analysis_data.get('news_analysis', {})
    if news_info and 'error' not in news_info and news_info.get('news_data'):
        news_data = news_info['news_data']
        content += f"**æ–°é—»æ€»æ•°**: {len(news_data)}æ¡\n\n"
        
        if news_data:
            content += "## æœ€æ–°æ–°é—»\n\n"
            for i, news in enumerate(news_data[:10], 1):  # æ˜¾ç¤ºæœ€æ–°10æ¡
                content += f"### {i}. {news.get('title', 'æ— æ ‡é¢˜')}\n\n"
                content += f"**å‘å¸ƒæ—¶é—´**: {news.get('time', 'N/A')}\n\n"
                content += f"**å†…å®¹æ‘˜è¦**: {news.get('content', 'æ— å†…å®¹')}\n\n"
                content += f"**æ¥æº**: {news.get('source', 'N/A')}\n\n"
                content += "---\n\n"
        
        # AIæ–°é—»åˆ†æ
        if news_info.get('ai_analysis'):
            ai_result = news_info['ai_analysis']
            if ai_result.get('report'):
                content += "## ğŸ¤– AIæ–°é—»åˆ†æ\n\n"
                content += f"{ai_result['report']}\n\n"
                content += f"*åˆ†æç”Ÿæˆæ—¶é—´: {ai_result.get('timestamp', 'N/A')}*\n\n"
    else:
        content += "æ–°é—»èµ„è®¯æ•°æ®è·å–å¤±è´¥æˆ–æš‚æ— ç›¸å…³æ–°é—»ã€‚\n\n"
    
    content += "---\n\n"
    
    # 4. ç­¹ç åˆ†æéƒ¨åˆ†
    content += """# ğŸ¯ ç­¹ç åˆ†æ

"""
    
    chip_info = analysis_data.get('chip_analysis', {})
    if chip_info and 'error' not in chip_info:
        content += "## ç­¹ç åˆ†å¸ƒæ•°æ®\n\n"
        
        # ç­¹ç æ•°æ®è¡¨æ ¼
        content += "| æŒ‡æ ‡åç§° | æ•°å€¼ |\n"
        content += "|----------|------|\n"
        
        chip_fields = [
            ('æœ€æ–°æ—¥æœŸ', 'latest_date'),
            ('è·åˆ©æ¯”ä¾‹', 'profit_ratio'),
            ('å¹³å‡æˆæœ¬', 'avg_cost'),
            ('90æˆæœ¬-ä½', 'cost_90_low'),
            ('90æˆæœ¬-é«˜', 'cost_90_high'),
            ('90é›†ä¸­åº¦', 'concentration_90'),
            ('70æˆæœ¬-ä½', 'cost_70_low'),
            ('70æˆæœ¬-é«˜', 'cost_70_high'),
            ('70é›†ä¸­åº¦', 'concentration_70'),
            ('æ”¯æ’‘ä½', 'support_level'),
            ('é˜»åŠ›ä½', 'resistance_level'),
            ('æˆæœ¬ä¸­å¿ƒ', 'cost_center')
        ]
        
        for display_name, field_name in chip_fields:
            value = chip_info.get(field_name)
            if value is not None:
                if isinstance(value, float):
                    if field_name in ['profit_ratio', 'concentration_90', 'concentration_70']:
                        value = f"{value:.2f}%"
                    else:
                        value = f"{value:.2f}"
            else:
                value = 'N/A'
            content += f"| {display_name} | {value} |\n"
        
        content += "\n"
        
        # ç­¹ç åˆ†ææŒ‡æ ‡
        analysis = chip_info.get('analysis', {})
        if analysis:
            content += "## ç­¹ç åˆ†ææŒ‡æ ‡\n\n"
            content += f"**è·åˆ©çŠ¶æ€**: {analysis.get('profit_status', 'N/A')}\n\n"
            content += f"**é›†ä¸­åº¦çŠ¶æ€**: {analysis.get('concentration_status', 'N/A')}\n\n"
            content += f"**é£é™©ç­‰çº§**: {analysis.get('risk_level', 'N/A')}\n\n"
        
        # AIç­¹ç åˆ†æ
        if 'chip_ai' in analysis_data:
            ai_result = analysis_data['chip_ai']
            if ai_result.get('analysis_result'):
                content += "## ğŸ¤– AIç­¹ç åˆ†æ\n\n"
                content += f"{ai_result['analysis_result']}\n\n"
                content += f"*åˆ†æç”Ÿæˆæ—¶é—´: {ai_result.get('timestamp', 'N/A')}*\n\n"
    else:
        content += "ç­¹ç åˆ†ææ•°æ®è·å–å¤±è´¥æˆ–è¯¥è‚¡ç¥¨ä¸æ”¯æŒç­¹ç åˆ†æã€‚\n\n"
    
    content += "---\n\n"
    
    # 5. ç»¼åˆåˆ†æéƒ¨åˆ†
    content += """# ğŸ¯ ç»¼åˆåˆ†æ

"""
    
    comprehensive_ai = analysis_data.get('comprehensive_analysis', {})
    if comprehensive_ai and comprehensive_ai.get('report'):
        content += "## ğŸ¤– AIç»¼åˆåˆ†æ\n\n"
        content += f"{comprehensive_ai['report']}\n\n"
        content += f"*åˆ†æç”Ÿæˆæ—¶é—´: {comprehensive_ai.get('timestamp', 'N/A')}*\n\n"
        
        # åˆ†æä¿¡æ¯
        analysis_info = comprehensive_ai.get('analysis_info', {})
        if analysis_info:
            content += "## åˆ†æä¿¡æ¯\n\n"
            content += f"**æ•°æ®æ¥æºæ•°é‡**: {analysis_info.get('data_sources_count', 0)}ä¸ª\n\n"
            content += f"**åˆ†ææ—¶é—´**: {analysis_info.get('analysis_time', 'N/A')}\n\n"
    else:
        content += "ç»¼åˆåˆ†ææ•°æ®è·å–å¤±è´¥æˆ–æœªè¿›è¡ŒAIç»¼åˆåˆ†æã€‚\n\n"
    
    # æ·»åŠ æŠ¥å‘Šç»“å°¾
    content += f"""---

## ğŸ“Š æŠ¥å‘Šæ€»ç»“

æœ¬æŠ¥å‘ŠåŸºäº {batch_info['start_time']} çš„æ‰¹é‡åˆ†æç»“æœç”Ÿæˆï¼ŒåŒ…å«äº† {stock_name}({stock_code}) çš„å®Œæ•´åˆ†ææ•°æ®ã€‚

**åˆ†æç»´åº¦**:
- âœ… åŸºæœ¬ä¿¡æ¯åˆ†æ
- âœ… è¡Œæƒ…èµ°åŠ¿åˆ†æ  
- âœ… æ–°é—»èµ„è®¯åˆ†æ
- âœ… ç­¹ç åˆ†æ
- âœ… ç»¼åˆåˆ†æ

**æ•°æ®æ¥æº**: XY Stock è‚¡ç¥¨åˆ†æç³»ç»Ÿ  
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**ç³»ç»Ÿç‰ˆæœ¬**: {version_info}

---

*æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚*
"""
    
    return content


def _generate_markdown_content(batch_data: Dict) -> str:
    """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹"""
    detailed = batch_data['detailed']
    summary = batch_data['summary']
    result_dir = batch_data['result_dir']
    
    # è·å–ç‰ˆæœ¬ä¿¡æ¯
    version_info = get_full_version()
    
    # åŸºæœ¬ä¿¡æ¯
    batch_info = detailed['batch_info']
    results = detailed['results']
    summary_stats = detailed['summary_stats']
    
    # å¼€å§‹ç”Ÿæˆå†…å®¹
    content = f"""# æ‰¹é‡è‚¡ç¥¨åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†ææ¦‚è§ˆ

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**åˆ†ææ—¶é—´**: {batch_info['start_time']} - {batch_info['end_time']}  
**æ€»è€—æ—¶**: {batch_info['total_duration']:.2f}ç§’  
**åˆ†æè‚¡ç¥¨æ•°**: {len(results)}  
**æˆåŠŸæ•°é‡**: {batch_info['success_count']}  
**å¤±è´¥æ•°é‡**: {batch_info['failed_count']}  
**æˆåŠŸç‡**: {(batch_info['success_count'] / len(results) * 100):.1f}%  

**ç³»ç»Ÿç‰ˆæœ¬**: {version_info}

---

## ğŸ“ˆ åˆ†æé…ç½®

- **åˆ†æç±»å‹**: {', '.join(batch_info['config']['analysis_types'])}
- **ä½¿ç”¨ç¼“å­˜**: {'æ˜¯' if batch_info['config']['use_cache'] else 'å¦'}
- **AIåˆ†æ**: {'å¯ç”¨' if batch_info['config']['include_ai_analysis'] else 'ç¦ç”¨'}
- **å¹¶å‘æ•°**: {batch_info['config']['max_workers']}
- **æœ€å¤§é‡è¯•**: {batch_info['config']['max_retry']}

---

## ğŸ“‹ è‚¡ç¥¨åˆ†æç»“æœ

"""
    
    # æ·»åŠ æ±‡æ€»è¡¨æ ¼
    if summary is not None:
        content += "### ç»“æœæ±‡æ€»è¡¨\n\n"
        content += "| è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | åˆ†æçŠ¶æ€ | å½“å‰ä»·æ ¼ | æ¶¨è·Œå¹…(%) | æŠ€æœ¯è¶‹åŠ¿ | RSIæ°´å¹³ | æ–°é—»æ•°é‡ | ç›ˆåˆ©æ¯”ä¾‹(%) | åˆ†æå®Œæˆæ•° | åŒ…å«AIåˆ†æ |\n"
        content += "|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|\n"
        
        for _, row in summary.iterrows():
            content += f"| {row['è‚¡ç¥¨ä»£ç ']} | {row['è‚¡ç¥¨åç§°']} | {row['åˆ†æçŠ¶æ€']} | {row['å½“å‰ä»·æ ¼']} | {row['æ¶¨è·Œå¹…(%)']} | {row['æŠ€æœ¯è¶‹åŠ¿']} | {row['RSIæ°´å¹³']} | {row['æ–°é—»æ•°é‡']} | {row['ç›ˆåˆ©æ¯”ä¾‹(%)']} | {row['åˆ†æå®Œæˆæ•°']} | {'æ˜¯' if row['åŒ…å«AIåˆ†æ'] else 'å¦'} |\n"
        
        content += "\n"
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    if summary_stats:
        content += "## ğŸ“Š ç»Ÿè®¡åˆ†æ\n\n"
        
        # è¡Œä¸šåˆ†å¸ƒ
        if summary_stats.get('industry_distribution'):
            content += "### è¡Œä¸šåˆ†å¸ƒ\n\n"
            industry_data = summary_stats['industry_distribution']
            for industry, count in industry_data.items():
                content += f"- **{industry}**: {count}åª\n"
            content += "\n"
        
        # ä»·æ ¼åŒºé—´åˆ†å¸ƒ
        if summary_stats.get('price_ranges'):
            content += "### ä»·æ ¼åŒºé—´åˆ†å¸ƒ\n\n"
            price_data = summary_stats['price_ranges']
            for price_range, count in price_data.items():
                content += f"- **{price_range}**: {count}åª\n"
            content += "\n"
        
        # æŠ€æœ¯è¶‹åŠ¿åˆ†å¸ƒ
        if summary_stats.get('trend_distribution'):
            content += "### æŠ€æœ¯è¶‹åŠ¿åˆ†å¸ƒ\n\n"
            trend_data = summary_stats['trend_distribution']
            for trend, count in trend_data.items():
                content += f"- **{trend}**: {count}åª\n"
            content += "\n"
    
    # æ·»åŠ è¯¦ç»†åˆ†æç»“æœ
    content += "## ğŸ“„ è¯¦ç»†åˆ†æç»“æœ\n\n"
    
    for i, result in enumerate(results, 1):
        if result['status'] == 'success':
            content += f"### {i}. {result['stock_name']} ({result['stock_code']})\n\n"
            
            # åŸºæœ¬ä¿¡æ¯
            summary_data = result.get('summary', {})
            if summary_data:
                content += f"**å½“å‰ä»·æ ¼**: {summary_data.get('current_price', 'N/A')}  \n"
                content += f"**æ¶¨è·Œå¹…**: {summary_data.get('change_percent', 'N/A')}%  \n"
                content += f"**æŠ€æœ¯è¶‹åŠ¿**: {summary_data.get('technical_trend', 'N/A')}  \n"
                content += f"**RSIæ°´å¹³**: {summary_data.get('rsi_level', 'N/A')}  \n"
                content += f"**æ–°é—»æ•°é‡**: {summary_data.get('news_count', 0)}  \n"
                content += f"**ç›ˆåˆ©æ¯”ä¾‹**: {summary_data.get('profit_ratio', 0)}%  \n"
                content += f"**åˆ†æå®Œæˆæ•°**: {summary_data.get('analysis_count', 0)}  \n"
                content += f"**åŒ…å«AIåˆ†æ**: {'æ˜¯' if summary_data.get('has_ai_analysis', False) else 'å¦'}  \n\n"
            
            # å¦‚æœæœ‰AIåˆ†æç»“æœï¼Œæ·»åŠ ç®€è¦æ‘˜è¦
            analysis_data = result.get('analysis_data', {})
            if analysis_data.get('comprehensive_ai'):
                ai_result = analysis_data['comprehensive_ai']
                if ai_result.get('analysis_result'):
                    content += f"**AIåˆ†ææ‘˜è¦**: {ai_result['analysis_result'][:200]}...\n\n"
            
            content += "---\n\n"
        else:
            content += f"### {i}. {result['stock_name']} ({result['stock_code']}) - åˆ†æå¤±è´¥\n\n"
            content += f"**é”™è¯¯ä¿¡æ¯**: {result.get('error_message', 'æœªçŸ¥é”™è¯¯')}\n\n"
            content += "---\n\n"
    
    # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
    content += "## ğŸ“ ç›¸å…³æ–‡ä»¶\n\n"
    content += f"**ç»“æœç›®å½•**: `{result_dir}`\n\n"
    
    files = os.listdir(result_dir)
    content += "**åŒ…å«æ–‡ä»¶**:\n"
    for file in sorted(files):
        content += f"- {file}\n"
    
    content += f"\n---\n\n*æŠ¥å‘Šç”± XY Stock ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
    
    return content


def _generate_error_report(error_msg: str, format_type: str) -> bytes:
    """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
    error_content = f"# æ‰¹é‡åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\n**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n*è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å®Œæ•´*"
    
    if format_type == "pdf":
        return generate_pdf_report(error_content)
    elif format_type == "docx":
        return generate_docx_report(error_content)
    elif format_type == "html":
        return generate_html_report(error_content)
    elif format_type == "markdown":
        return generate_markdown_file(error_content)
    else:
        return error_content.encode('utf-8')


# ä¾¿æ·å‡½æ•°
def generate_batch_report_from_dir(result_dir: str, format_type: str = "pdf") -> bytes:
    """ä»ç»“æœç›®å½•ç”Ÿæˆæ‰¹é‡åˆ†ææŠ¥å‘Š"""
    return generate_batch_analysis_report(result_dir, format_type)


def generate_batch_reports(batch_result_dir: str, format_type: str = "markdown", report_type: str = "individual") -> List[str]:
    """
    ç”Ÿæˆæ‰¹é‡åˆ†ææŠ¥å‘Šï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        batch_result_dir: æ‰¹é‡åˆ†æç»“æœç›®å½•
        format_type: æŠ¥å‘Šæ ¼å¼ (pdf, docx, html, markdown)
        report_type: æŠ¥å‘Šç±»å‹ ('individual'=ä¸ªè‚¡æŠ¥å‘Š, 'summary'=æ±‡æ€»æŠ¥å‘Š, 'both'=ä¸¤è€…)
    
    Returns:
        ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    generated_files = []
    
    try:
        if report_type in ['individual', 'both']:
            # ç”Ÿæˆä¸ªè‚¡æŠ¥å‘Š
            files = export_all_individual_reports(batch_result_dir, format_type)
            generated_files.extend(files)
        
        if report_type in ['summary', 'both']:
            # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
            report_content = generate_batch_analysis_report(batch_result_dir, format_type)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"batch_analysis_report_{timestamp}.{format_type}"
            filepath = os.path.join(batch_result_dir, filename)
            
            with open(filepath, 'wb') as f:
                f.write(report_content)
            
            generated_files.append(filepath)
            print(f"âœ… æ‰¹é‡åˆ†ææ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
        
        return generated_files
        
    except Exception as e:
        print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        return []


if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python batch_report.py <ç»“æœç›®å½•> [æ ¼å¼] [æ¨¡å¼]")
        print("æ ¼å¼: pdf, docx, html, markdown")
        print("æ¨¡å¼: batch(æ‰¹é‡æŠ¥å‘Š) æˆ– individual(ä¸ªè‚¡æŠ¥å‘Šï¼Œé»˜è®¤)")
        print("")
        print("ç¤ºä¾‹:")
        print("  python batch_report.py batch_analysis_results/20251016_194726 pdf")
        print("  python batch_report.py batch_analysis_results/20251016_194726 pdf individual")
        print("  python batch_report.py batch_analysis_results/20251016_194726 docx batch")
        sys.exit(1)
    
    result_dir = sys.argv[1]
    format_type = sys.argv[2] if len(sys.argv) > 2 else "pdf"
    mode = sys.argv[3] if len(sys.argv) > 3 else "individual"
    
    if not os.path.exists(result_dir):
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ {result_dir}")
        sys.exit(1)
    
    try:
        if mode == "batch":
            # ç”Ÿæˆæ‰¹é‡æ±‡æ€»æŠ¥å‘Š
            report_content = generate_batch_analysis_report(result_dir, format_type)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"batch_analysis_report_{timestamp}.{format_type}"
            
            with open(filename, 'wb') as f:
                f.write(report_content)
            
            print(f"âœ… æ‰¹é‡åˆ†ææ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
            
        else:
            # ç”Ÿæˆä¸ªè‚¡ç‹¬ç«‹æŠ¥å‘Š
            print(f"ğŸš€ å¼€å§‹ç”Ÿæˆä¸ªè‚¡ç‹¬ç«‹æŠ¥å‘Š...")
            print(f"ğŸ“ ç»“æœç›®å½•: {result_dir}")
            print(f"ğŸ“„ æ ¼å¼: {format_type.upper()}")
            print("=" * 50)
            
            generated_files = export_all_individual_reports(result_dir, format_type)
            
            print("=" * 50)
            print(f"âœ… ä¸ªè‚¡æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
            print(f"ğŸ“Š å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæŠ¥å‘Šæ–‡ä»¶")
            print("")
            print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            for filepath in generated_files:
                print(f"  - {os.path.basename(filepath)}")
        
    except Exception as e:
        print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        sys.exit(1)
